{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lfirenzeg/msds602labs/blob/main/LFMG_07_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rd2QZetSDszc"
      },
      "source": [
        "# **Assignment 7**\n",
        "\n",
        "# **Weeks 8 & 9 - Pandas**\n",
        "* In this homework assignment, you will explore and analyze a public dataset of your choosing. Since this assignment is “open-ended” in nature, you are free to expand upon the requirements below. However, you must meet the minimum requirments as indicated in each section.\n",
        "\n",
        "* You must use Pandas as the **primary tool** to process your data.\n",
        "\n",
        "* The preferred method for this analysis is in a .ipynb file. Feel free to use whichever platform of your choosing.  \n",
        " * https://www.youtube.com/watch?v=inN8seMm7UI (Getting started with Colab).\n",
        "\n",
        "* Your data should need some \"work\", or be considered \"dirty\".  You must show your skills in data cleaning/wrangling.\n",
        "\n",
        "### **Headings or comments**\n",
        "**You are required to make use of comments, or headings for each section.  You must explain what your code is doing, and the results of running your code.**  Act as if you were giving this assignment to your manager - you must include clear and descriptive information for each section.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uW3w6p8rqgxu"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "In this section, please describe the dataset you are using.  Include a link to the source of this data.  You should also provide some explanation on why you choose this dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0PnfMOFzOXz"
      },
      "source": [
        "Given the upcoming winter season 2024-2025, I wanted to review historical data of snowfall in New York city. The dataset used in this analysis contains snow precipitation recoded in LaGuardia airport, in NYC, covering multiple decades of snowfall data. It provides detailed information on the amount of snow recorded for each month (July through June) and the total snowfall for each season. The dataset's nature allows for a variety of data wrangling and analysis techniques, from handling missing data to creating new features.\n",
        "\n",
        "**Source of the Data:**\n",
        "The data is hosted on GitHub: [Snow Records Dataset](https://https://raw.githubusercontent.com/Lfirenzeg/msds602labs/refs/heads/main/Assignment_7/snow_records_ny.csv)\n",
        "\n",
        "**Original source:** [National Weather Service](https://https://www.weather.gov/wrh/Climate?wfo=okx)\n",
        "The dataset includes the following key columns:\n",
        "\n",
        "**Year**: The winter season (e.g., \"1939-1940\").\n",
        "\n",
        "**Monthly Columns**: Snowfall records for each month.\n",
        "\n",
        "**Season**: Total snowfall recorded for the entire season."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bp8cdDxDs2t"
      },
      "source": [
        "______________\n",
        "# Data Exploration\n",
        "Import your dataset into your .ipynb, create dataframes, and explore your data.  \n",
        "\n",
        "Include:\n",
        "\n",
        "* Summary statistics means, medians, quartiles,\n",
        "* Missing value information\n",
        "* Any other relevant information about the dataset.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OJmbafkEhhq",
        "outputId": "bbb30154-8fb2-4e8c-bd06-dfedb0857921",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Importing required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset directly from the given URL\n",
        "url = 'https://raw.githubusercontent.com/Lfirenzeg/msds602labs/refs/heads/main/Assignment_7/snow_records_ny.csv'\n",
        "snow_data = pd.read_csv(url)\n",
        "\n",
        "# Initial exploration of the dataset\n",
        "print(\"First exploration:\")\n",
        "print(snow_data.head(), \"\\n\")\n",
        "print(\"Summary Statistics:\")\n",
        "print(snow_data.describe())\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First exploration:\n",
            "        Year Jul Aug Sep Oct  Nov  Dec  Jan   Feb   Mar  Apr May Jun Season\n",
            "0  1939-1940   M   M   M   M    M    M  3.9   8.3   1.5  1.2   0   0      M\n",
            "1  1940-1941   0   0   0   0  1.5  0.9  9.5   2.5  15.6    0   0   0     30\n",
            "2  1941-1942   0   0   0   0    0  0.1    3     T   0.5    0   0   0    3.6\n",
            "3  1942-1943   0   0   0   0    T  2.6  6.4   1.7   4.7    T   0   0   15.4\n",
            "4  1943-1944   0   0   0   0    T    T  5.5  10.1   4.6  3.8   0   0     24 \n",
            "\n",
            "Summary Statistics:\n",
            "             Year Jul Aug Sep Oct Nov Dec  Jan Feb Mar Apr May Jun Season\n",
            "count          85  85  85  85  85  85  85   85  85  85  85  85  85     85\n",
            "unique         85   3   3   2   5  17  55   67  68  50  18   2   2     77\n",
            "top     1939-1940   0   0   0   0   T   T  2.2   T   T   T   0   0   14.6\n",
            "freq            1  80  83  84  73  37  11    4   7  15  33  78  83      2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0WTKtqozNn1"
      },
      "source": [
        "#As we can see in the initial exploration, there are some issues that need to be addressed to clean the data:\n",
        "# - All columns are currently read as object (likely because they contain non-numeric entries such as \"M\" or \"T\").\n",
        "# - Placeholders such as \"M\" (for missing) and \"T\" (trace amounts of snow) need special handling.\n",
        "#   \"M\" values will be replaced with Nan, and \"T\" values will be replaced with small ammount of snow (in this case we'll use 0.01)\n",
        "#   Numeric columns will be convert to the appropriate type, except for year."
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCSLIafaEGVK"
      },
      "source": [
        "# Data Wrangling - SOLVED\n",
        "Create a subset of your original data and perform the following.  \n",
        "\n",
        "1. Modify multiple column names.\n",
        "**Solution:**\n",
        "The column names for months were changed from their three-letter abbreviations to their full names using the rename method.\n",
        "\n",
        "2. Look at the structure of your data – are any variables improperly coded? Such as strings or characters? Convert to correct structure if needed.\n",
        "**Solution**\n",
        "Numeric columns were converted to appropriate types after replacing non-numeric placeholders (\"M\" and \"T\") with NaN and 0.01, respectively.\n",
        "\n",
        "3. Fix missing and invalid values in data.\n",
        "**Solution**\n",
        "* Missing values represented by \"M\" were replaced with NaN.\n",
        "* \"T\" (trace amounts) was replaced with 0.01.\n",
        "* Any remaining missing values were filled with 0 for practical analysis\n",
        "\n",
        "4. Create new columns based on existing columns or calculations.\n",
        "**Solution**\n",
        "A new column, Winter_Total, was created to calculate the total snowfall for the core winter months (December, January, February).\n",
        "\n",
        "5. Drop column(s) from your dataset.\n",
        "**Solution**\n",
        "As an example, code to drop June is included (since  deemed unnecessary).\n",
        "\n",
        "6. Drop a row(s) from your dataset.\n",
        "**Solution**\n",
        "Dropping rows where Total_Season snowfall is 0 (if not meaningful).\n",
        "\n",
        "7. Sort your data based on multiple variables.\n",
        "**Solution**\n",
        "Sorting was applied based on Total_Season and Winter_Total in descending order.\n",
        "\n",
        "8. Filter your data based on some condition.\n",
        "**Solution**\n",
        "Filtering was performed to include seasons with total snowfall over 50 inches.\n",
        "\n",
        "9. Convert all the string values to upper or lower cases in one column.\n",
        "**Solution**\n",
        "In this assignment, all the columns are numeric values. However, if the Year column was written with letter instead, the code to change the entire column to uppercase would be:\n",
        "snow_data_filled['Year'] = snow_data_filled['Year'].str.upper()\n",
        "\n",
        "10. Check whether numeric values are present in a given column of your dataframe.\n",
        "**Solution**\n",
        "The code checks if numeric values are present in the Year column.\n",
        "\n",
        "11. Group your dataset by one column, and get the mean, min, and max values by group.\n",
        "  * Groupby()\n",
        "  * agg() or .apply()\n",
        "\n",
        "**Solution**\n",
        "Grouping by decades was done, with calculations for the mean, min, and max values.\n",
        "\n",
        "12. Group your dataset by two columns and then sort the aggregated results within the groups.\n",
        "**Solution**\n",
        "\n",
        "**You are free (and should) to add on to these questions.  Please clearly indicate in your assignment your answers to these questions.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VWWvvynEiQT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cff92b90-a889-4b23-dddf-4887807c6271"
      },
      "source": [
        "# Cleaning data: replacing placeholders \"M\" (missing) with NaN and \"T\" (trace) with a small numerical value\n",
        "snow_data_cleaned = snow_data.replace({\"M\": np.nan, \"T\": 0.01})\n",
        "\n",
        "# Converting numeric columns (all except Year) to appropriate types\n",
        "columns_to_convert = snow_data_cleaned.columns[1:]  # Exclude 'Year'\n",
        "snow_data_cleaned[columns_to_convert] = snow_data_cleaned[columns_to_convert].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Renaming columns for clarity and consistency\n",
        "snow_data_cleaned.rename(\n",
        "    columns={\n",
        "        \"Jul\": \"July\",\n",
        "        \"Aug\": \"August\",\n",
        "        \"Sep\": \"September\",\n",
        "        \"Oct\": \"October\",\n",
        "        \"Nov\": \"November\",\n",
        "        \"Dec\": \"December\",\n",
        "        \"Jan\": \"January\",\n",
        "        \"Feb\": \"February\",\n",
        "        \"Mar\": \"March\",\n",
        "        \"Apr\": \"April\",\n",
        "        \"May\": \"May\",\n",
        "        \"Jun\": \"June\",\n",
        "        \"Season\": \"Total_Season\"\n",
        "    },\n",
        "    inplace=True\n",
        ")\n",
        "\n",
        "# Handling missing values: filling with 0 for now (as snow records are often 0)\n",
        "snow_data_filled = snow_data_cleaned.fillna(0)\n",
        "\n",
        "# Creating a new column for total winter snowfall (December, January, February)\n",
        "snow_data_filled['Winter_Total'] = (\n",
        "    snow_data_filled['December'] +\n",
        "    snow_data_filled['January'] +\n",
        "    snow_data_filled['February']\n",
        ")\n",
        "\n",
        "# Dropping the 'June' column as an example (since it only has 0s)\n",
        "snow_data_filled = snow_data_filled.drop(columns=['June'])\n",
        "\n",
        "# Dropping rows where Total_Season is 0\n",
        "snow_data_filled = snow_data_filled[snow_data_filled['Total_Season'] != 0]\n",
        "# However right now this code is not removing rows, since the least ammount of\n",
        "# snow recorded in a season was 1.9\n",
        "\n",
        "# Sorting data by \"Total_Season\" and \"Winter Total\" in descending order\n",
        "sorted_snow_data = snow_data_filled.sort_values(by=['Total_Season', 'Winter_Total'], ascending=[False, False])\n",
        "\n",
        "# Filtering for seasons with total snowfall over 50 inches\n",
        "filtered_snow_data = snow_data_filled[snow_data_filled['Total_Season'] > 50]\n",
        "\n",
        "# Grouping by decades and calculating mean, min, and max snowfall\n",
        "snow_data_filled['Decade'] = (snow_data_filled['Year'].str[:4].astype(int) // 10) * 10\n",
        "decade_grouped = snow_data_filled.groupby('Decade')['Total_Season'].agg(['mean', 'min', 'max'])\n",
        "\n",
        "# Checking for numeric values in the 'Year' column\n",
        "numeric_check = snow_data_filled['Year'].str.isnumeric().any()\n",
        "\n",
        "# Grouping by Decade and Winter_Total, then sorting\n",
        "grouped_decade_winter = snow_data_filled.groupby(['Decade', 'Winter_Total']).agg({'Total_Season': ['mean', 'min', 'max']})\n",
        "sorted_grouped_decade_winter = grouped_decade_winter.sort_values(by=[('Total_Season', 'mean')], ascending=False)\n",
        "\n",
        "# Displaying the final results\n",
        "print(\"Does the Year column contain numeric values?\", numeric_check)\n",
        "print(\"\\nSnow Records Dataset with Renamed Columns and Filled Missing Values:\")\n",
        "print(snow_data_filled.head())\n",
        "print(\"\\nSnow Records Dataset Sorted by Total Season Snowfall:\")\n",
        "print(sorted_snow_data.head())\n",
        "print(\"\\nFiltered Snow Records Dataset (Total Season > 50 Inches):\")\n",
        "print(filtered_snow_data)\n",
        "print(\"\\nSnow Records Grouped by Decade:\")\n",
        "print(decade_grouped)\n",
        "print(\"\\nSnow Records Grouped by Decade and Winter Total, then sorted:\")\n",
        "print(sorted_grouped_decade_winter)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Does the Year column contain numeric values? False\n",
            "\n",
            "Snow Records Dataset with Renamed Columns and Filled Missing Values:\n",
            "        Year  July  August  September  October  November  December  January  \\\n",
            "1  1940-1941   0.0     0.0        0.0     0.00      1.50      0.90      9.5   \n",
            "2  1941-1942   0.0     0.0        0.0     0.00      0.00      0.10      3.0   \n",
            "3  1942-1943   0.0     0.0        0.0     0.00      0.01      2.60      6.4   \n",
            "4  1943-1944   0.0     0.0        0.0     0.00      0.01      0.01      5.5   \n",
            "5  1944-1945   0.0     0.0        0.0     0.01      0.01      7.10     14.3   \n",
            "\n",
            "   February  March  April  May  Total_Season  Winter_Total  Decade  \n",
            "1      2.50  15.60   0.00  0.0          30.0         12.90    1940  \n",
            "2      0.01   0.50   0.00  0.0           3.6          3.11    1940  \n",
            "3      1.70   4.70   0.01  0.0          15.4         10.70    1940  \n",
            "4     10.10   4.60   3.80  0.0          24.0         15.61    1940  \n",
            "5      9.20   0.01   0.01  0.0          30.6         30.60    1940  \n",
            "\n",
            "Snow Records Dataset Sorted by Total Season Snowfall:\n",
            "         Year  July  August  September  October  November  December  January  \\\n",
            "56  1995-1996   0.0     0.0        0.0     0.00      2.40      17.7     27.6   \n",
            "8   1947-1948   0.0     0.0        0.0     0.00      0.01      26.2     18.3   \n",
            "54  1993-1994   0.0     0.0        0.0     0.00      0.00      10.4     13.0   \n",
            "21  1960-1961   0.0     0.0        0.0     0.01      0.00      15.3     15.5   \n",
            "75  2014-2015   0.0     0.0        0.0     0.00      0.40       1.3     19.7   \n",
            "\n",
            "    February  March  April   May  Total_Season  Winter_Total  \n",
            "56      18.5   11.5    0.2  0.00          77.9          63.8  \n",
            "8       14.9    4.2    0.0  0.00          63.6          59.4  \n",
            "54      25.6    9.5    0.0  0.00          58.5          49.0  \n",
            "21      21.3    3.8    0.6  0.01          56.5          52.1  \n",
            "75      15.1   17.3    0.0  0.00          53.8          36.1  \n",
            "\n",
            "Filtered Snow Records Dataset (Total Season > 50 Inches):\n",
            "         Year  July  August  September  October  November  December  January  \\\n",
            "8   1947-1948   0.0     0.0        0.0     0.00      0.01      26.2     18.3   \n",
            "18  1957-1958   0.0     0.0        0.0     0.00      0.01      11.0      8.8   \n",
            "21  1960-1961   0.0     0.0        0.0     0.01      0.00      15.3     15.5   \n",
            "54  1993-1994   0.0     0.0        0.0     0.00      0.00      10.4     13.0   \n",
            "56  1995-1996   0.0     0.0        0.0     0.00      2.40      17.7     27.6   \n",
            "63  2002-2003   0.0     0.0        0.0     0.01      0.01      13.6      4.2   \n",
            "71  2010-2011   0.0     0.0        0.0     0.00      0.01      14.0     32.6   \n",
            "74  2013-2014   0.0     0.0        0.0     0.00      0.20       7.6     16.7   \n",
            "75  2014-2015   0.0     0.0        0.0     0.00      0.40       1.3     19.7   \n",
            "\n",
            "    February  March  April   May  Total_Season  Winter_Total  \n",
            "8       14.9    4.2   0.00  0.00          63.6          59.4  \n",
            "18      12.3   18.9   0.50  0.00          51.5          32.1  \n",
            "21      21.3    3.8   0.60  0.01          56.5          52.1  \n",
            "54      25.6    9.5   0.00  0.00          58.5          49.0  \n",
            "56      18.5   11.5   0.20  0.00          77.9          63.8  \n",
            "63      24.2    3.4   5.60  0.00          51.0          42.0  \n",
            "71       4.1    0.9   0.01  0.00          51.6          50.7  \n",
            "74      27.2    0.4   0.30  0.00          52.4          51.5  \n",
            "75      15.1   17.3   0.00  0.00          53.8          36.1  \n",
            "\n",
            "Snow Records Grouped by Decade:\n",
            "          mean   min   max\n",
            "Decade                    \n",
            "1940    29.730   3.6  63.6\n",
            "1950    22.970  11.3  51.5\n",
            "1960    27.760  14.5  56.5\n",
            "1970    18.900   1.9  43.5\n",
            "1980    22.050  10.8  32.8\n",
            "1990    26.440   7.1  77.9\n",
            "2000    31.340   3.4  51.0\n",
            "2010    31.570   4.6  53.8\n",
            "2020    18.625   3.4  35.3\n",
            "\n",
            "Snow Records Grouped by Decade and Winter Total, then sorted:\n",
            "                    Total_Season            \n",
            "                            mean   min   max\n",
            "Decade Winter_Total                         \n",
            "1990   63.80                77.9  77.9  77.9\n",
            "1940   59.40                63.6  63.6  63.6\n",
            "1990   49.00                58.5  58.5  58.5\n",
            "1960   52.10                56.5  56.5  56.5\n",
            "2010   36.10                53.8  53.8  53.8\n",
            "...                          ...   ...   ...\n",
            "       4.61                  4.6   4.6   4.6\n",
            "1940   3.11                  3.6   3.6   3.6\n",
            "2000   3.31                  3.4   3.4   3.4\n",
            "2020   3.31                  3.4   3.4   3.4\n",
            "1970   1.91                  1.9   1.9   1.9\n",
            "\n",
            "[84 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nATPKSaNXD9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusions  \n",
        "\n",
        "After exploring your dataset, provide a short summary of what you noticed from this dataset.  What would you explore further with more time?"
      ],
      "metadata": {
        "id": "tujjevRpXEen"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Trends:**\n",
        "\n",
        "We find that there is significant variation in total seasonal snowfall across years, with some seasons experiencing over 70 inches of snow and others recording minimal snowfall.\n",
        "\n",
        "The winter months (December, January, and February) consistently contribute the most snowfall, as expected.\n",
        "\n",
        "**Variation by decades**\n",
        "\n",
        "Grouping by decades reveals a trend of fluctuating average snowfall over time, suggesting changes in weather patterns or data recording practices. The decade with the most snowfall is 2010s, with a total snowfall of 315.7 inches.\n",
        "\n",
        "\n",
        "**Further Exploration**\n",
        "\n",
        "Possible paths for exploration could include looking into long-term snowfall trends to detect any statistically significant increases or decreases in snowfall over the decades, potentially indicating climate change effects.\n",
        "\n",
        "With additional data, we could study correlations between snowfall and external factors like temperature, or rain precipitation.\n"
      ],
      "metadata": {
        "id": "AxGdMlPuVIpi"
      }
    }
  ]
}